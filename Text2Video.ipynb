{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7184484-9801-4b91-bdcb-f75f9b22ad0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from spacy.lang.en import English\n",
    "import torch\n",
    "from diffusers import AutoPipelineForText2Image\n",
    "from diffusers import DiffusionPipeline\n",
    "from diffusers.utils import load_image, export_to_video\n",
    "from PIL import Image\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import Markdown\n",
    "\n",
    "\n",
    "sp = spacy.load(\"en_core_web_sm\")\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "pipeline_text2image = AutoPipelineForText2Image.from_pretrained(\"stabilityai/sdxl-turbo\")\n",
    "pipeline_image2video = DiffusionPipeline.from_pretrained(\"stabilityai/stable-video-diffusion-img2vid-xt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c9e1c3-ba53-42fc-8c33-ebf3f7bfcbf3",
   "metadata": {},
   "source": [
    "# Process Article to Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ce28a1-cf43-4ab2-a87d-9ebd5d7efd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sentences(text):\n",
    "    # Load the English tokenizer from spaCy\n",
    "    nlp = English()\n",
    "    nlp.add_pipe('sentencizer')\n",
    "\n",
    "    # Process the text\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Extract sentences and store them in an array\n",
    "    sentences = [sent.text.strip() for sent in doc.sents]\n",
    "\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4807ed6c-1ea3-4b91-9ad5-65ff69dd21fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_patterns(sentence):\n",
    "    #keep the need words\n",
    "    pos_needed = {\"VERB\", \"ADJ\", \"ADV\", \"ADP\", \"NOUN\", \"NUM\"}\n",
    "    sentence_tags = []\n",
    "    for word in sp(sentence):\n",
    "        if word.text.lower() in stop_words and word.pos_ != \"ADP\":\n",
    "            continue\n",
    "        if word.pos_ == \"PROPN\":\n",
    "            word.pos_ = \"NOUN\"\n",
    "        if word.pos_ in pos_needed:    \n",
    "            sentence_tags.append((word.text, word.pos_))\n",
    "    \n",
    "    # Initialize the list for results\n",
    "    res = []\n",
    "\n",
    "    # Iterate over tagged words in the sentence\n",
    "    i = 0\n",
    "    while i < len(sentence_tags):\n",
    "        word, pos = sentence_tags[i]\n",
    "\n",
    "        # Check for pattern 1: \"ADP\" + ... + \"NOUN\"\n",
    "        if pos == \"ADP\":\n",
    "            for j in range(i + 1, len(sentence_tags)):\n",
    "                if sentence_tags[j][1] == \"NOUN\":\n",
    "                    res.append(\" \".join([w for w, p in sentence_tags[i:j+1]]))\n",
    "                    i = j  # Update the index to the end of the pattern\n",
    "                    break\n",
    "\n",
    "        # Check for pattern 2: \"ADV\" + (\"VERB\") \n",
    "        elif pos == \"ADV\":\n",
    "            if i < len(sentence_tags) - 1 and sentence_tags[i+1][1] == \"VERB\":\n",
    "                res.append(word + \" \" + sentence_tags[i+1][0])\n",
    "                i += 1  # Skip the next word as it's already included in the pattern\n",
    "            else:\n",
    "                res.append(word)\n",
    "                \n",
    "        elif pos == \"VERB\":\n",
    "            if i < len(sentence_tags) - 1 and sentence_tags[i+1][1] == \"ADV\":\n",
    "                res.append(word + \" \" + sentence_tags[i+1][0])\n",
    "                i += 1  # Skip the next word as it's already included in the pattern\n",
    "            else:\n",
    "                res.append(word)\n",
    "            \n",
    "        # Check for pattern 3: \"ADJ\" + ... + \"NOUN\" or \"NOUN\"\n",
    "        elif pos == \"ADJ\":\n",
    "            has_noun = False\n",
    "            for j in range(i + 1, len(sentence_tags)):\n",
    "                if sentence_tags[j][1] == \"NOUN\":\n",
    "                    res.append(\" \".join([w for w, p in sentence_tags[i:j+1]]))\n",
    "                    i = j  # Update the index to the end of the pattern\n",
    "                    has_noun = True\n",
    "                    break\n",
    "            if not has_noun:\n",
    "                res.append(word)\n",
    "            \n",
    "        elif pos == \"NOUN\":\n",
    "            res.append(word)\n",
    "\n",
    "        \n",
    "        i += 1\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790fefd8-7772-4602-8726-d20c3c5b11b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_prompt(article):\n",
    "    prompt = []\n",
    "    general_prompt = \"best quality,ultra-detailed,masterpiece,hires,8k,\"\n",
    "    sentences = split_sentences(article)\n",
    "    seen = set()\n",
    "    for sentence in sentences:\n",
    "        for p in extract_patterns(sentence):\n",
    "            if p in seen:\n",
    "                continue\n",
    "            seen.add(p)\n",
    "            prompt.append(p)\n",
    "            \n",
    "    return general_prompt + \",\".join(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71557344-bfd2-4f02-b4e8-e740a2a84207",
   "metadata": {},
   "outputs": [],
   "source": [
    "article = \"In Africa's vast savannah, a swift cheetah races, epitomizing nature's splendor. Its effortless sprint highlights not just its remarkable speed but also the urgent need to protect these majestic creatures and their diminishing habitats.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ec5fea-a381-4256-8d10-010be4ac4908",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = to_prompt(article)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301eaf9a-f283-4307-82c0-007be7aa584b",
   "metadata": {},
   "source": [
    "# Prompt to Image (SDXL Turbo) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586bf860-b4c4-4dba-ac78-ae45070d0da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = \"cheetah\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8362bad3-e315-4ba8-bc40-b8a8fc9c5e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = pipeline_text2image(prompt=prompt, guidance_scale=0.0, num_inference_steps=10, height=576, width=1024).images[0]\n",
    "image.save(f\"{topic}.png\")\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1520d19b-6479-4c0c-83d1-743d171e40fe",
   "metadata": {},
   "source": [
    "# Image to Video (Stable Video Diffusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0492750-44e7-4c51-a4c4-543d48c027c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and resize the input image\n",
    "image = Image.open(f\"{topic}.png\")\n",
    "image = image.resize((1024, 576))  # Resize image to 1024x576\n",
    "\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05faf00-cfd4-478e-ac8f-8eec1ec98e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline.enable_model_cpu_offload() #if you can use gpu\n",
    "generator = torch.manual_seed(42)\n",
    "frames = pipeline_image2video(image, decode_chunk_size=8, generator=generator).frames[0]\n",
    "\n",
    "export_to_video(frames, f\"{topic}.mp4\", fps=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02153f79-d994-4309-bf06-1daf7b913ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'your_video.mp4' with the path to your video file\n",
    "video = VideoFileClip(f\"{topic}.mp4\") \n",
    "\n",
    "# Replace 'output.gif' with the desired output file name\n",
    "video.write_gif(f\"{topic}.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c9ac88-ff52-4e5e-9469-2237935f404f",
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_text = f'![SegmentLocal]({topic}.gif \"segment\")'\n",
    "\n",
    "Markdown(markdown_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4350570f-7bce-41ac-8042-767cdc2af6ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
